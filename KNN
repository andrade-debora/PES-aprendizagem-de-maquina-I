# ====================================================================================================
# Nome do Arquivo : KNN.py
# Autores         : Débora Leandro de Andrade e Juan Diego de Paula Rollemberg
# Curso           : PES - Colaborador Embraer
# Disciplina      : Aprendizagem de máquina I
# Professor       : George Darmilton
# Data            : 03/08/2025                                                
# ====================================================================================================

"""
Esse script tem como objetivo ler o dataset selecionado e aplicar o algoritmo Naive Bayes.
É realizado um treinamento considerando todos os atributos.       
"""

#%% Imports ==========================================================================================

# Utilidades
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Classes do modelo de aprendizado
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import label_binarize

# Acesso ao dataset
from sklearn.datasets import fetch_openml

# Funções de avaliação dos modelos
from sklearn.metrics import (classification_report, 
                             ConfusionMatrixDisplay, 
                             confusion_matrix, 
                             roc_auc_score, 
                             roc_curve, auc, 
                             accuracy_score,
                             precision_score)

from sklearn.model_selection import KFold, cross_val_score
from sklearn.model_selection import train_test_split


#%% Inicio do programa ==========================================================================================
# Lê o dataset como dataframe
dataset_sklearn = fetch_openml(name="air-quality-and-pollution-assessment", version=1, as_frame=True)
dataset = dataset_sklearn.frame

#%% Pré-visualização do dataset
dataset.head()

#%% Resumo do dataset
dataset.describe()

#%% Mapeando os valores da classe para inteiro (para fins de visualização da região de decisão)
dataset['Air_Quality'] = pd.factorize(dataset['Air_Quality'])[0]
''' 
Moderate - 0
Good  - 1 
Hazardous - 2 
Poor - 3
'''

#%% Matriz de correlação - Todos os atributo
correlation_matrix = dataset.corr()

plt.figure(figsize=(15, 10))
ax = sns.heatmap(
    correlation_matrix,
    annot=True,
    cmap="coolwarm",
    linewidths=0.5,
    annot_kws={"size": 14},
)

plt.title("Correlação com a variável alvo", fontsize=20)
plt.tight_layout()
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

# Aumentar fonte da legenda (colorbar)
colorbar = ax.collections[0].colorbar
colorbar.ax.tick_params(labelsize=14)

plt.show()
    

#%% Primeiro treinamento ==========================================================================================
# Todos os atributos são considerados
# -----------------------------------------------------------

# Define os atributos e a variável alvo
target_column='Air_Quality'
X = dataset.drop(columns=target_column)
y = dataset[target_column]

# Define a semente
seed=42

# Divide o dataset em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)

print("Shape conjunto de treino:", X_train.shape)
print("Shape conjunto de teste:", X_test.shape)


# #%% Algoritmo iterativo para escolher melhor N e métrica

metrics_to_eval = ["euclidean", "manhattan"]
N_to_eval = [5, 10, 20, 40, 70, 100]

acuracia = np.zeros((len(metrics_to_eval), len(N_to_eval)))
precisao = np.zeros((len(metrics_to_eval), len(N_to_eval)))

melhor_acuracia = float('-inf')
melhor_precisao = float('-inf')
melhor_metrica = None
melhor_N = None
melhor_metrica_index = None
melhor_N_index = None

for i, m in enumerate(metrics_to_eval):
    for j, n in enumerate(N_to_eval):
        
        KNN_model = KNeighborsClassifier(n_neighbors=n, metric=m)
        KNN_model.fit(X_train, y_train)

        y_pred = KNN_model.predict(X_test)
        
        acuracia[i,j] = accuracy_score(y_test, y_pred)
        precisao[i,j] = precision_score(y_test, y_pred, average='weighted') 
        
        if acuracia[i,j] > melhor_acuracia:
            melhor_acuracia = acuracia[i,j]
            melhor_metrica = m
            melhor_N = n
            melhor_metrica_index = i
            melhor_N_index = j

print("O melhor valor para N é:", melhor_N)
print("A melhor métrica é:", melhor_metrica)
print("Para esse N e essa métrica, temos:")
print("Acurácia:", acuracia[melhor_metrica_index,melhor_N_index])
print("Precisão ponderada:", precisao[melhor_metrica_index,melhor_N_index])# %%

        
#%% Modelo escolhido
KNN_model = KNeighborsClassifier(n_neighbors=melhor_N, metric=melhor_metrica)
KNN_model.fit(X_train, y_train)

y_pred = KNN_model.predict(X_test)

# Avaliação preliminar
print(classification_report(y_test, y_pred))

#%% Avaliacao: #1 Matriz de confusao
cm = confusion_matrix(y_test, y_pred, labels=KNN_model.classes_)
print(cm)

print(f"\n Labels:{KNN_model.classes_} \n")

#display_labels - define como será a ordem das classes na matriz
disp_cm = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=KNN_model.classes_)
disp_cm.plot()

#%% Avaliacao: #2 Curvas ROC

# Obtem as probabilidades preditas
y_pred_prob = KNN_model.predict_proba(X_test)

# Ordena as classes para a binarização
classes = sorted(y.unique())

# Transforma o vetor teste em formato binário
y_test_bin = label_binarize(y_test, classes=classes)

# Calcula as curvas ROC para cada classe
plt.figure(figsize=(10, 8))
for i in range(len(classes)):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Classe {classes[i]} (AUC = {roc_auc:.2f})', linewidth=3)

plt.plot([0, 1], [0, 1], 'k--', linewidth=2)
plt.xlabel('Taxa de Falsos Positivos', fontsize=14)
plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=14)
plt.title('Curvas ROC - KNN por Classe', fontsize=16)
plt.legend(loc='lower right',fontsize=12)
plt.grid(True)

plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

plt.show()


#%% Avaliação: #3 Validação Cruzada - K Fold, K=10

kf = KFold(n_splits=10)

scores = cross_val_score(KNN_model, X, y, cv=kf, scoring='accuracy')

print("Acurácias por fold:", scores)
print("Acurácia média:", scores.mean())
print("K-fold: %.3f ± %.3f" % (scores.mean(), scores.std()))

#%% Avaliação: #4 Relatório de classificação e métricas
report = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report).transpose().iloc[:-1]  # Remover 'accuracy' e 'macro avg'

plt.figure(figsize=(10, 6))
report_df[['precision', 'recall', 'f1-score']].plot(kind='bar')
plt.title("Precisão, Recall e F1-Score por Classe - KNN, N = 10")
plt.xlabel("Classe")
plt.ylabel("Valor")
plt.xticks(rotation=0)
plt.grid(True)
plt.tight_layout()
plt.show()

